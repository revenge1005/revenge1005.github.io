---
title:  "[Retry, k8s] 23. 컨피그 & 스토리지 API - 영구 볼륨(PV)" 

categories:
  - KUBERNETES
tags:
  - [kubernetes]

toc: true
toc_sticky: true

date: 2023-10-15
last_modified_at: 2023-10-15
---
<br>

# 🔔 영구 볼륨 종류
---

<style>
table {
    font-size: 12pt;
}
table th:first-of-type {
    width: 5%;
}
table th:nth-of-type(2) {
    width: 15%;
}
table th:nth-of-type(3) {
    width: 50%;
}
table th:nth-of-type(4) {
    width: 30%;
}
</style>

**시작하기 전 선행 작업 및 확인해야할 내용** <br> - **<https://revenge1005.github.io/kubernetes/ch03-6-1/>** <br> - **<https://revenge1005.github.io/kubernetes/ch03-6-2/>** <br> - **<https://revenge1005.github.io/kubernetes/ch03-6-3/>**
{: .notice--warning}

+ 영구 볼륨은 네트워크를 통해 디스크를 Attach(어태치)하는 디스크 타입이다.

+ 영구 볼륨은 플러거블(pluggable)한 구조로 되어 있으며 다음과 같은 플로그인이 있다.

    - GCE Persistent DisK

    - AWS Elastic Block Store

    - Azure File

    - nfs

    - iSCSI

    - Ceph(RBD, CephFS)

    - OpenStack Cinder (지원 중단?)

    - GlusterFS (지원 중단)

    - Container Storage Interface(CSI)


<br>

## (1) Container Storage Interface(CSI)

> CSI는 컨테이너 오케스트레이션 시스템과 스토리지 시스템 간의 통신을 위한 인터페이스로, 이를 통해 컨테이너 오케스트레이션 시스템에서 스토리지 프로비저닝, 볼륨 연결 및 마운트, 스냅샷 및 복원, 확장 및 축소와 같은 기능을 제공한다.

<br>
  
### 📜 CSI 종류 

> 이 외에도 많은 종류의 CSI 드라이버들이 있으며, 각각의 스토리지 시스템에 맞게 최적화된 기능과 성능을 제공한다.

|종류|개요|
|---|---|
|Azure Disk CSI Driver|Azure 디스크를 쿠버네티스에서 사용할 수 있게 해주는 CSI 드라이버|
|Azure File CSI Driver|Azure 파일을 쿠버네티스에서 사용할 수 있게 해주는 CSI 드라이버|
|AWS EBS CSI Driver|AWS EBS(Elastic Block Store)를 쿠버네티스에서 사용할 수 있게 해주는 CSI 드라이버|
|GCE PD CSI Driver|Google Compute Engine의 영구 디스크를 쿠버네티스에서 사용할 수 있게 해주는 CSI 드라이버|
|CephFS CSI Driver|CephFS를 쿠버네티스에서 사용할 수 있게 해주는 CSI 드라이버|
|RBD CSI Driver|RBD(RADOS Block Device)를 쿠버네티스에서 사용할 수 있게 해주는 CSI 드라이버|
|NFS CSI Driver|NFS(Network File System)를 쿠버네티스에서 사용할 수 있게 해주는 CSI 드라이버|

<br>
  
### 📜 영구 볼륨

+ 예제를 실행하기 위해서는 k8s 클러스터의 모든 노드에 ceph-common 패키지 설치, Ceph 관리자 키를 k8s 시크릿으로 생성해야 한다.

+ Ceph 관리자 키 시크릿 생성은 <https://revenge1005.github.io/kubernetes/ch03-6-3/> 해당 주소 대로 구성했다면 할 필요 없다.

```bash
apiVersion: v1
kind: PersistentVolume
metadata:
  name: sample-pv
  labels:
    type: ceph-pv
    environment: stg
spec:
  capacity:
    storage: 1Gi
  accessModes:
  - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: csi-fs-sc
  cephfs:
    monitors:
      - "192.168.219.51:6789"
    secretRef:
      name: csi-fs-secret
```

<br>

#### 【레이블】

+ 동적 프로비저닝을 사용하지 않고 PV를 생성하는 경우, PV 종류를 알 수 없게 되기 때문에 type/environment/speed 등의 레이블을 사용한다.

+ 레이블을 사용하면, **PVC에서 레이블로 볼륨을 지정할 수 있기 때문에 사용 목적에 맞도록 유연하게 스케줄링**을 할 수 있다.


![01](https://user-images.githubusercontent.com/42735894/231078262-04b259f7-d471-46f7-a97b-cd24d2186fa9.png){: width="100%" height="100%"}{: .align-center}

<br>

#### 【용량】

+ 용량을 지정할 때 주의해야 할 점은 동적 프로비저닝을 사용할 수 없는 환경에서는 작은 용량의 PV도 준비해 두어야 한다는 것이다.

+ **PVC 요청이 3GiB인 경우에는 준비된 VP에서 가장 비슨한 용량인 10GiB 볼륨이 할당된다.(사용하지 않는 7GiB 용량이 함께 할당됨)**


![02](https://user-images.githubusercontent.com/42735894/231080195-c5ed382c-f4ec-4f1d-ac0a-bdc90b0d645f.png){: width="70%" height="70%"}{: .align-center}

<br>

#### 【접근 모드】

|모드|설명|
|---|---|
|ReadWriteOnce(RWO)|단일 노드에서 Read/Write 가능|
|ReadOnlyMany(ROX)|여러 노드에서 Read 가능|
|ReadWriteMany(RWX)|여러 노드에서 Read/Write 가능|


![03](https://user-images.githubusercontent.com/42735894/231078522-c209d57d-bde9-4913-b76f-14367e0b0733.png){: width="100%" height="100%"}{: .align-center}

<br>

#### 【Reclaim Policy】

+ Reclaim Policy는 **PVC이 삭제되었을 때 PV에 대한 처리 방법을 제어하는 정책**이다.

|설정|설명|
|---|---|
|Delte|ㆍ PVC을 삭제했을 때 PV 자체도 동시에 삭제된다. <br><br>ㆍ PVC 리소스를 삭제해도 PV 리소스는 Released 상태로 남는다.|
|Retain|ㆍ PVC을 삭제했을 때 PV 자체를 삭제하지 않고 그대로 유지한다. <br><br>ㆍ PVC 리소스를 삭제하더라도 PV 리소스는 Released 상태로 남는다.<br><br>ㆍ 다른 PVC에 할당할 수 없기 때문에 다시 같은 디스크를 할당할 경우, 새로운 PV를 생성해야 한다.|
|Recycle|ㆍ PV 데이터를 삭제하고 재사용 가능한 상태로 만든다.<br><br>ㆍ 다른 PVC에서 다시 마운트 가능, 이 정책은 k8s에서 더 이상 사용하지 않는다.|


![04](https://user-images.githubusercontent.com/42735894/231078637-6cc66022-7708-4fbf-9b30-08f5096bf657.png){: width="90%" height="90%"}{: .align-center}


![05](https://user-images.githubusercontent.com/42735894/231078694-2d679d5e-0d0d-48e9-bb6a-63965a96f2f0.png){: width="90%" height="90%"}{: .align-center}


![06](https://user-images.githubusercontent.com/42735894/231078703-55c746f5-d5d8-4c76-a52e-59e824fe7da0.png){: width="90%" height="90%"}{: .align-center}

<br>

#### 【스토리지클래스】

+ **스토리지 클래스는 스토리지를 프로비저닝하여 관리하는 방법을 정의하는 개념으로, 클러스터 내부 또는 외부 스토리지를 관리할 수 있는 방법을 지정**한다.

+ PVC는 스토리지 클래스를 지정하여 어떤 스토리지를 프로비저닝할지 결정하고, 해당 PVC의 요구에 따라 스토리지를 동적으로 할당하며, 실제 스토리지를 나타내는 PV가 생성된다.

+ 스토리지 클래스를 사용하면 클러스터의 스토리지 자원을 효율적으로 관리할 수 있으며, 필요한 스토리지 자원을 동적으로 할당하여 유연한 스토리지 관리가 가능하다.

<br>

#### 【볼륨 타입별 설정(Ceph)】

- 예제에서는 Cephfs를 사용했지만 설정 항목은 영구 볼륨 플러그인마다 다르다.

```bash
cephfs: # 볼륨 타입 추가
    monitors: # CephFS 모니터의 IP 주소 목록
      - "192.168.0.1:6789"
      - "192.168.0.2:6789"
      - "192.168.0.3:6789"
    path: "/sample" # CephFS 내의 경로 (선택적)
    user: "admin" # Ceph 사용자 이름 (선택적)
    secretRef: # Ceph 관리자 키를 포함하는 시크릿의 참조 (선택적)
      name: "ceph-secret"
    readOnly: false # 읽기 전용 여부 (선택적)
```

<br>