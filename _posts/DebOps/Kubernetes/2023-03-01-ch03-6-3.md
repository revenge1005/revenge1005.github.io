---
title:  "[Retry, k8s] 06-3. 온프레미스 환경에서 SDS에 의한 동적 볼륨 프로비저닝(CephFS) - (3)"

categories:
  - KUBERNETES
tags:
  - [kubernetes]

toc: true
toc_sticky: true

date: 2023-09-02
last_modified_at: 2023-09-02
---
# [Retry, k8s] 06-3. 온프레미스 환경에서 SDS에 의한 동적 볼륨 프로비저닝(CephFS) - (3)
---

<style>
table {
    font-size: 12pt;
}
table th:first-of-type {
    width: 5%;
}
table th:nth-of-type(2) {
    width: 15%;
}
table th:nth-of-type(3) {
    width: 50%;
}
table th:nth-of-type(4) {
    width: 30%;
}
</style>

<br>

## 🔔 kubernetes에 ceph-csi 구성 (Helm chart로 설치하고 사용하기)

> [(해당 페이지 참고함)](https://devocean.sk.com/blog/techBoardDetail.do?ID=163924) ceph-csi는 ceph 커뮤니티에서 kubernetes의 저장소 인터페이스를 구현한 [ceph용 구현체](https://github.com/ceph/ceph-csi)이다. <br><br>
Ceph CSI 플러그인은 container orchestrator(kubernetes)와 ceph 클러스터간 인터페이스에 대한 구현이다. <br><br>
eph 볼륨을 동적으로 배포하고 워크로드와 연결시킨고, ceph의 다양한 제공기능인 [rbd(rbd 문서 참조)](https://github.com/ceph/ceph-csi/blob/devel/docs/deploy-rbd.md)와 [cephfs 볼륨(cephFS 문서참조)](https://github.com/ceph/ceph-csi/blob/devel/docs/deploy-cephfs.md), nfs 볼륨을 지원한다.

<br>

### (1) Helm repo

> <https://github.com/ceph/ceph-csi/tree/devel/charts/ceph-csi-cephfs>

```bash
root@k8s-master:~# helm repo add ceph-csi https://ceph.github.io/csi-charts


root@k8s-master:~# helm search repo ceph-csi
NAME                            CHART VERSION   APP VERSION     DESCRIPTION                                       
ceph-csi/ceph-csi-cephfs        3.6.1           3.6.1           Container Storage Interface (CSI) driver, provi...
ceph-csi/ceph-csi-rbd           3.6.1           3.6.1           Container Storage Interface (CSI) driver, provi...helm repo add ceph-csi https://ceph.github.io/csi-charts
```


### (2) 환경반영

> Helm 설치를 위해 환경에 맞도록 값 재지정(value-override) 파일을 준비하자. 전체 값은 다음 링크(<https://github.com/ceph/ceph-csi/tree/devel/charts/ceph-csi-rbd#configuration>)에서 확인 가능하고 여기서는 기본적으로 연결한 ceph 클러스터에 대한 monitor만 지정한다. 그 외 storage class등을 지정할 수 있으나 여기서는 다음 단계에서 따로 추가한다.

```bash
root@k8s-master:~# cat <<EOF > ceph-csi.vo
csiConfig:
- clusterID: "3adf5d85-7d69-455d-82cf-f799e63981e4"
  monitors:
  - "192.168.219.51:6789"
EOF
```


### (3) 설치하기 (테스트 환경에 따라 다르지만 설치하는데 시간이 좀 걸림)

```bash
root@k8s-master:~# kubectl create namespace "ceph-csi-cephfs"

root@k8s-master:~# helm install --namespace "ceph-csi-cephfs" "ceph-csi-cephfs" ceph-csi/ceph-csi-cephfs -f ceph-csi.vo

root@k8s-master:~# kubectl get all -n ceph-csi-cephfs
```


### (4) secret 구성 및 배포

> **★ 주의-1 : 23-09-01 (k8s 1.28버전, ceph-csi 3.9.0 버전) 기준 - 이전 버전까지는 secret을 아무 곳이나 저장해도 해당 예제가 잘되었으나, 현재 최신 버전에서는 kube-system에만 저장해야 한다. <br><br> 만약 다른 곳에 저장하면 해당 에러 발생 : "unable to get monitor info from DNS SRV with service name: ceph-mon [errno 2] RADOS object not found (error connecting to the cluster)"**

> **★ 주의-2 : k8s 1.28 버전 부터는 cephfs, rbd는 "deprecated(더 이상 사용되지 않음) [(k8s 볼륨 문서 cephfs)](https://kubernetes.io/docs/concepts/storage/volumes/#cephfs), [(k8s 볼륨 문서 rbd)](https://kubernetes.io/docs/concepts/storage/volumes/#rbd)" 표시되어 있지만, ceph-csi를 통해서는 아직 사용 가능하다.<br><br> 이후 지원이 계속 될 수도 있고, 안될 수 도 있으니 k8s 공식 문서와 ceph-csi(github) 프로젝트를 확인하자.**

```bash
# userkey는 ceph 클러스트의 관리 노드에서 "ceph auth list" 명령으로 확인
root@k8s-master:~# cat csi-fs-secret.yaml 
---
apiVersion: v1
kind: Secret
metadata:
  name: csi-fs-secret
  namespace: kube-system
stringData:
  userID: cephfs
  userKey: AQBgJ1Rg9DMzEhAA/y3+g2tDGHOujxPVjFHS6A==
  adminID: admin
  adminKey: AQBs/FJgC6z2OhAAoPp0WFfPvhp0DiLEKk01xw==


root@k8s-master:~# kubectl apply -f csi-fs-secret.yaml 
```


### (5) StorageClass 구성 및 배포하고

```bash
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
   name: csi-fs-sc
allowVolumeExpansion: true
provisioner: cephfs.csi.ceph.com
parameters:
   clusterID: 3adf5d85-7d69-455d-82cf-f799e63981e4
   fsName: kubernetes
   csi.storage.k8s.io/controller-expand-secret-name: csi-fs-secret
   csi.storage.k8s.io/controller-expand-secret-namespace: kube-system
   csi.storage.k8s.io/provisioner-secret-name: csi-fs-secret
   csi.storage.k8s.io/provisioner-secret-namespace: kube-system
   csi.storage.k8s.io/node-stage-secret-name: csi-fs-secret
   csi.storage.k8s.io/node-stage-secret-namespace: kube-system
reclaimPolicy: Delete
mountOptions:
   - debug

root@k8s-master:~# kubectl apply -f csi-fs-sc.yaml 
```


### (6) pvc 생성 및 배포

```bash
root@k8s-master:~# cat fs-pvc.yaml 
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: csi-cephfs-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  storageClassName: csi-fs-sc


root@k8s-master:~# kubectl apply -f fs-pvc.yaml 
```


### (7) 확인

```bash
# k8s 클러스터의 마스터 노드에서 확인
root@k8s-master:~# kubectl get sc,pvc,pv
NAME                                    PROVISIONER           RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
storageclass.storage.k8s.io/csi-fs-sc   cephfs.csi.ceph.com   Delete          Immediate           true                   2m3s

NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/csi-cephfs-pvc   Bound    pvc-2a95b26a-df5b-4d36-b13e-7f1ed6791b35   1Gi        RWX            csi-fs-sc      106s

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   REASON   AGE
persistentvolume/pvc-2a95b26a-df5b-4d36-b13e-7f1ed6791b35   1Gi        RWX            Delete           Bound    default/csi-cephfs-pvc   csi-fs-sc               103s
```


### (8) pod 생성 및 배포

```bash
root@k8s-master:~# cat pod.yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: csi-cephfs-demo-pod
spec:
  containers:
    - name: web-server
      image: docker.io/library/nginx:latest
      volumeMounts:
        - name: mypvc
          mountPath: /var/lib/www
  volumes:
    - name: mypvc
      persistentVolumeClaim:
        claimName: csi-cephfs-pvc
        readOnly: false


root@k8s-master:~# kubectl apply -f fs-pvc.yaml 


root@k8s-master01:~/k8s# kubectl get all,sc,pvc,pv
NAME                      READY   STATUS    RESTARTS   AGE
pod/csi-cephfs-demo-pod   1/1     Running   0          9s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   3h18m

NAME                                    PROVISIONER           RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
storageclass.storage.k8s.io/csi-fs-sc   cephfs.csi.ceph.com   Delete          Immediate           true                   2m3s

NAME                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/csi-cephfs-pvc   Bound    pvc-2a95b26a-df5b-4d36-b13e-7f1ed6791b35   1Gi        RWX            csi-fs-sc      106s

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   REASON   AGE
persistentvolume/pvc-2a95b26a-df5b-4d36-b13e-7f1ed6791b35   1Gi        RWX            Delete           Bound    default/csi-cephfs-pvc   csi-fs-sc               103s
```

<br>