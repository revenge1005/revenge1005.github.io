---
title:  "[시스템 관리] 06. 로그 감시법" 

categories:
  - SYS_MGMT
tags:
  - [sys_mgmt, linux]

toc: true
toc_sticky: true

date: 2023-07-07
last_modified_at: 2023-07-07
---
<br>

# 🔔 로그 감시법
---

<style>
table {
    font-size: 12pt;
}
table th:first-of-type {
    width: 5%;
}
table th:nth-of-type(2) {
    width: 20%;
}
table th:nth-of-type(3) {
    width: 50%;
}
table th:nth-of-type(4) {
    width: 30%;
} 
big { 
    font-size: 25px 
}
small { 
    font-size: 18px 
}
</style>

<br>

<big> **■ 시각으로 범위를 좁힌다.** </big> <br>

1. 로그 확인 시, 장애가 발생한 시각 부근의 메시지를 확인한다.

2. cat, less 명령 대신 tail 또는 head를 사용하여 파일의 일부만 출력하여 시스템 부하를 줄일 수 있고, nice나 ionice와 같은 낮은 우선순위로 실행하면 부하를 더 낮출 수 있다.

3. 로그를 확인할 때 모든 메시지가 장애 원인은 아니라는 점을 주의해야 한다.

4. 장애 전후로 계속 나오는 메시지는 노이즈(장애와 직접 관계가 없는 메시지)일 수 있다.

5. 노이즈를 제외하고 추출 대상을 확인하기 위해서는 grep의 -v 옵션(검색 패턴과 일치하지 않는 라인을 출력)을 사용하는 것이 좋다.

```bash
# 예시용 /var/log/messages 내용
Jun 4 20:00:01 Server dhclient: DHCPREQUEST on eth0 to 192.168.1.1
Jun 4 20:01:10 Server kernel: Error - Connection timeout
Jun 4 20:02:22 Server app: Application started
Jun 4 20:02:45 Server dhclient: DHCPACK from 192.168.1.1
Jun 4 20:03:05 Server app: Error - Database connection failed
Jun 4 20:03:40 Server dhclient: bound to 192.168.1.100 -- renewal in 500 seconds.
Jun 4 20:04:15 Server app: Error - Invalid input data
Jun 4 20:04:58 Server dhclient: DHCPREQUEST on eth0 to 192.168.1.1
Jun 4 20:05:25 Server kernel: Error - Disk I/O error
```

```bash
# 예시 1)
$ tail -n 1000 /var/log/messages | grep "Jun 4 20:0[0-5]"
# 또는
$ nice -n 19 ionice -c3 tail -n 1000 /var/log/messages | grep "Jun 4 20:0[0-5]"

Jun 4 20:02:22 Server app: Application started
Jun 4 20:02:45 Server dhclient: DHCPACK from 192.168.1.1
Jun 4 20:03:05 Server app: Error - Database connection failed
Jun 4 20:03:40 Server dhclient: bound to 192.168.1.100 -- renewal in 500 seconds.
Jun 4 20:04:15 Server app: Error - Invalid input data
```

```bash
# 예시 2)
$ tail -n 1000 /var/log/messages | grep "Jun 4 20:0[0-5]" | grep -v "dhclient"

Jun 4 20:02:22 Server app: Application started
Jun 4 20:03:05 Server app: Error - Database connection failed
Jun 4 20:04:15 Server app: Error - Invalid input data
```

<br>

<big> **■ 키워드로 범위를 좁힌다.** </big> <br>

1. 시각으로만 범위를 좁히는 것은 대량의 로그가 출력된 경우에는 효과적이지 않을 수 있으므로, 키워드를 사용하여 범위를 좁힌다.

2. 장애 원인을 추측할 수 있다면, 해당 장애 발생 시 출력되는 문자열을 미리 알아두고, 이를 바탕으로 검색하는 것이 빠를 수 있지만 검색 문자열이 구체적이면 다른 메시지까지 필터링될 수 있으므로 이 방법은 사전 연습 정도로만 이용하는 것이 좋다.

3. 미지의 오류 발생 시 자주 출력되는 로그 레벨 문자열을 키워드로 사용하는 것이 좋다. 일반적인 로그 레벨 문자열은 다음과 같다.

    | 로그 레벨 | 의미 |
    | :-----: | :------- |
    | Fatal, Critical | 치명적인 오류 장애 |
    | Error | 치명적인 오류 정보 또는 오류 정보 |
    | Warning | 경고 정보 |
    | Info, Note, Notice | 일반적인 (조작) 정보 |
    | Debug, Trace | 디버그 정보 |

4. 로그 레벨 문자열은 소프트웨어별로 약간씩 다르므로, 로그 레벨의 사양을 파악하거나 찾기 쉬운 패턴을 지정해야 한다. (예시: warn(약자 표기), warning(소문자 표기))

5. 검색에서 쉽게 찾을 수 있도록 grep의 -i 옵션(대소문자를 구별하지 않고 검색)을 사용하는 것이 좋다.

```bash
# 예시용 /var/log/httpd/error_log 내용
[Jun 4 20:05:10] [error] [client 192.168.1.100] server reached MaxClients, shutting down
[Jun 4 20:06:15] [warn] [client 192.168.1.101] Request header is too large
[Jun 4 20:06:30] [info] [client 192.168.1.102] Successfully connected to database
[Jun 4 20:07:05] [error] [client 192.168.1.103] File not found: /var/www/html/page.html
[Jun 4 20:08:20] [warn] [client 192.168.1.104] Connection timeout to server
```

```bash
# 예시 1)
$ tail -n 1000 /var/log/httpd/error_log | grep "server reached MaxClients"

[Jun 4 20:05:10] [error] [client 192.168.1.100] server reached MaxClients, shutting down
```

```bash
# 예시 2)
$ tail -n 1000 /var/log/httpd/error_log | grep -i "warn"

[Jun 4 20:06:15] [warn] [client 192.168.1.101] Request header is too large
[Jun 4 20:08:20] [warn] [client 192.168.1.104] Connection timeout to server
```

<br>

<big> **■ 메시지 양을 주목한다.** </big> <br>

1. 서비스에 문제가 생겼지만 오류 메시지에 아무것도 출력되지 않는 경우, 요청 대비 시스템 처리 성능이 부족한 것이 원인일 수 있으므로 메시지 양을 비교하여 확인해야 한다.

2. 시각별로 액세스 로그를 집계하면 액세스 증감을 알 수 있으며, uniq -c의 결과를 가시화하는 도구인 c2g를 이용하거나 Cacti나 Munin과 같은 감시 도구를 사용하여 데이터를 쉽게 시각화할 수 있다.

3. 액세스한 소스 IP 주소별로 집계하면 어떤 IP 주소에서 액세스가 많았는지 알 수 있으며, 특정 IP 주소의 접속이 극단적으로 많을 경우, 부정 액세스나 검색 엔진 로봇에 의한 스캔일 수 있으므로 주의해야 한다.

4. 메시지 양을 비교하는 대상은 신중해야 하는데, 할인판매 등으로 인해 하루 중 액세스가 많은 경우, 수 분 전의 메시지양과 비교하더라도 액세스 증가라고 판단할 수 없으며 사흘 전, 일주일 전과 같이 일반적인 액세스 상황과 비교하여 판단하는 것이 중요하다.

5. 서비스 사용자가 증가하면서 액세스가 많아지는 경우, 서버 튜닝이나 스펙업으로 대처해야 한다.


```bash
# 예시 1)
$ tail -10000 access_log | grep "05/jun/2014" | cut -d ':' -f 2,3 | sort | uniq -c

    383 09:35
   3253 09:36
   1120 09:37
   1196 09:38
    933 09:39
    355 09:40
    348 09:41
    219 09:42
    370 09:43
    218 09:44
    313 09:45 
```

```bash
$ tail -10000 access_log | grep "05/jun/2014:09:36" | awk '{print $1}' | sort -n | uniq -c | sort

    6 198.51.10.1
    8 198.51.10.2
   34 198.51.10.3
   40 198.51.10.4 
  130 198.51.10.5 
 3000 198.51.10.6 
```